import time
import numpy as np
import torch
import torch.nn as nn
from torch.autograd import Variable
import pyupbit

# Upbit API 접근 정보
access_key = 
secret_key = 

# UpbitAPI 클래스 정의
class UpbitAPI:
    def __init__(self, access_key, secret_key):
        self.access_key = access_key
        self.secret_key = secret_key
        self.upbit_client = pyupbit.Upbit(self.access_key, self.secret_key)

    def get_current_price(self, symbol):
        ticker_info = pyupbit.get_orderbook(tickers=symbol)[0]["orderbook_units"][0]["ask_price"]
        return ticker_info

    def get_market_list(self):
        return pyupbit.get_tickers(fiat="KRW")

    def get_balance(self, symbol):
        return self.upbit_client.get_balance(symbol)

    def buy_market_order(self, symbol, budget):
        return self.upbit_client.buy_market_order(symbol, budget)

    def get_order_status(self, order_id):
        return self.upbit_client.get_order(order_id)['state']

    def sell_market_order(self, symbol, volume):
        return self.upbit_client.sell_market_order(symbol, volume)

# MuZero 신경망 구조
class MuZeroNetwork(nn.Module):
    def __init__(self, state_size, action_size):
        super(MuZeroNetwork, self).__init__()
        self.state_size = state_size
        self.action_size = action_size
        self.hidden_size = 32

        # 상태 인코더
        self.state_encoder = nn.Sequential(
            nn.Linear(state_size, self.hidden_size),
            nn.ReLU(),
            nn.Linear(self.hidden_size, self.hidden_size),
            nn.ReLU()
        )

        # 동적 모델
        self.dynamic_model = nn.GRUCell(self.hidden_size, self.hidden_size)

        # 상태 모델
        self.state_model = nn.Sequential(
            nn.Linear(self.hidden_size, self.hidden_size),
            nn.ReLU(),
            nn.Linear(self.hidden_size, state_size)
        )

        # 정책 모델
        self.policy_model = nn.Sequential(
            nn.Linear(self.hidden_size, self.hidden_size),
            nn.ReLU(),
            nn.Linear(self.hidden_size, action_size),
            nn.Softmax(dim=1)
        )

        # 가치 모델
        self.value_model = nn.Sequential(
            nn.Linear(self.hidden_size, self.hidden_size),
            nn.ReLU(),
            nn.Linear(self.hidden_size, 1)
        )

    def initial_inference(self, state):
        encoded_state = self.state_encoder(state)
        hidden_state = torch.zeros(1, self.hidden_size)
        return encoded_state, hidden_state

    def recurrent_inference(self, encoded_state, hidden_state, action):
        hidden_state = self.dynamic_model(encoded_state, hidden_state)
        predicted_state = self.state_model(hidden_state)
        predicted_policy = self.policy_model(hidden_state)
        predicted_value = self.value_model(hidden_state)
        return predicted_state, predicted_policy, predicted_value, hidden_state

    def get_weights(self):
        return self.state_encoder.state_dict(), self.dynamic_model.state_dict(), \
               self.state_model.state_dict(), self.policy_model.state_dict(), \
               self.value_model.state_dict()

    def set_weights(self, state_encoder_weights, dynamic_model_weights,
                    state_model_weights, policy_model_weights, value_model_weights):
        self.state_encoder.load_state_dict(state_encoder_weights)
        self.dynamic_model.load_state_dict(dynamic_model_weights)
        self.state_model.load_state_dict(state_model_weights)
        self.policy_model.load_state_dict(policy_model_weights)
        self.value_model.load_state_dict(value_model_weights)

# MuZero 알고리즘
class MuZero:
    def __init__(self, state_size, action_size):
        self.state_size = state_size
        self.action_size = action_size
        self.model = MuZeroNetwork(state_size, action_size)
        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)

    def predict(self, state):
        encoded_state, hidden_state = self.model.initial_inference(state)
        predicted_policy = self.model.policy_model(hidden_state)
        predicted_value = self.model.value_model(hidden_state)
        return predicted_policy, predicted_value

    def train(self, states, actions, rewards, next_states):
        self.optimizer.zero_grad()

        # 손실 계산
        loss = self.calculate_loss(states, actions, rewards, next_states)

        # 역전파 및 가중치 업데이트
        loss.backward()
        self.optimizer.step()

    def calculate_loss(self, states, actions, rewards, next_states):
        loss = 0
        discounted_reward = 0
        hidden_state = None

        for t in reversed(range(len(states))):
            state = states[t]
            action = actions[t]
            reward = rewards[t]
            next_state = next_states[t]

            encoded_state, hidden_state = self.model.initial_inference(state)
            _, _, value, hidden_state = self.model.recurrent_inference(encoded_state, hidden_state, action)

            predicted_next_state, predicted_policy, predicted_value, _ = self.model.recurrent_inference(
                encoded_state, hidden_state, action
            )

            loss += (value - reward) ** 2

            # 상태 모델 손실
            loss += nn.MSELoss()(predicted_next_state, Variable(torch.FloatTensor(next_state)))

            # 정책 모델 손실
            target_policy = self.get_target_policy(predicted_policy, action)
            loss += nn.MSELoss()(predicted_policy, Variable(torch.FloatTensor(target_policy)))

            # 가치 모델 손실
            target_value = self.get_target_value(rewards[t:])
            loss += nn.MSELoss()(predicted_value, Variable(torch.FloatTensor(target_value)))

            discounted_reward = reward + discounted_reward * 0.99

        return loss

    def get_target_policy(self, predicted_policy, action):
        target_policy = np.zeros(self.action_size)
        target_policy[action] = 1.0
        return target_policy

    def get_target_value(self, rewards):
        target_value = np.zeros(len(rewards) + 1)
        cumulative_reward = 0
        for i in reversed(range(len(rewards))):
            cumulative_reward = rewards[i] + cumulative_reward * 0.99
            target_value[i] = cumulative_reward
        return target_value[:-1]

    def act(self, state):
        policy, value = self.predict(state)

        # 확률적으로 행동 선택
        action = np.random.choice(self.action_size, p=np.squeeze(policy.detach().numpy()))
        return action, value.item()

def play_game(agent, upbit_api):
    states = []
    actions = []
    rewards = []
    next_states = []

    # 게임 진행
    state = initial_balance = 10000, upbit_api.get_current_price('BTC-KRW')
    done = False
    while not done:
        # 상태 저장
        states.append(state)

        # 행동 선택
        action, value = agent.act(state)
        actions.append(action)

        # 행동 실행
        if action == 1:
            # Trade
            target_coins = upbit_api.get_market_list()  # 모든 상장된 코인 가져오기
            best_coin = None
            best_returns = -1.0

            for coin in target_coins:
                if coin == 'KRW-BTC':
                    continue  # BTC는 거래하지 않음

                # 시장가 매수
                coin_price = upbit_api.get_current_price(coin)
                coin_budget = state[0] * 0.99
                coin_volume = coin_budget / coin_price
                order_id = upbit_api.buy_market_order(coin, coin_budget)
                if order_id is None:
                    # Failed to place an order
                    reward = -10.0
                else:
                    # Wait for the order to be filled
                    filled = False
                    while not filled:
                        status = upbit_api.get_order_status(order_id)
                        if status == 'filled':
                            filled = True
                            break
                        elif status == 'canceled' or status == 'expired':
                            # The order is canceled or expired
                            reward = -10.0
                            break

                    if filled:
                        coin_balance = upbit_api.get_balance(coin)
                        coin_value = coin_balance * coin_price
                        returns = (coin_value - coin_budget) / coin_budget

                        if returns > best_returns:
                            best_returns = returns
                            best_coin = coin

            if best_coin is None:
                # 수익이 나는 코인이 없는 경우 Hold
                action = 0
                reward = 0.0
            else:
                # 가장 높은 수익률을 갖는 코인으로 트레이딩
                coin_price = upbit_api.get_current_price(best_coin)
                coin_budget = state[0] * 0.99
                coin_volume = coin_budget / coin_price
                order_id = upbit_api.buy_market_order(best_coin, coin_budget)

                if order_id is None:
                    # Failed to place an order
                    action = 0
                    reward = 0.0
                else:
                    # Wait for the order to be filled
                    filled = False
                    while not filled:
                        status = upbit_api.get_order_status(order_id)
                        if status == 'filled':
                            filled = True
                            break
                        elif status == 'canceled' or status == 'expired':
                            # The order is canceled or expired
                            action = 0
                            reward = 0.0
                            break

                    if filled:
                        coin_balance = upbit_api.get_balance(best_coin)
                        coin_value = coin_balance * coin_price

                        if coin_value >= coin_budget * 1.005:
                            reward = 1.0
                        elif coin_value <= coin_budget * 0.995:
                            reward = -1.0
                        else:
                            reward = 0.1

                        state[0] -= coin_budget
                        state[0] += coin_value

        else:
            # Hold
            reward = 0.0

        rewards.append(reward)

        next_state = [state[0], upbit_api.get_current_price('BTC-KRW')]
        next_states.append(next_state)

        state = next_state

    if len(states) >= max_steps_per_episode: 
            done = True

    time.sleep(1)

    return states, actions, rewards, next_states

# 게임 반복 횟수
num_episodes = 1000

# 최대 에피소드 단계 수
max_steps_per_episode = 100

# UpbitAPI 인스턴스 생성
upbit_api = UpbitAPI(access_key, secret_key) 

# Set state_size and action_size based on your environment
state_size = 2  # Example: Set the state size to 2
action_size = 2  # Example: Set the action size to 2

# MuZero 인스턴스 생성
agent = MuZero(state_size, action_size)

# 게임 반복
for i in range(num_episodes):
    states, actions, rewards, next_states = play_game(agent, upbit_api)

    agent.train(states, actions, rewards, next_states)

    balance = upbit_api.get_balance('KRW')
    returns = sum(rewards) / len(rewards)

    if returns >= 0.005:
        coins = upbit_api.get_market_list()
        for coin in coins:
            if coin == 'KRW-BTC':
                continue

            coin_balance = upbit_api.get_balance(coin)
            if coin_balance > 0:
                upbit_api.sell_market_order(coin + '-KRW', coin_balance)
                print(f'{i+1}/{num_episodes}: Profit! Sold {coin} {coin_balance} at {upbit_api.get_current_price(coin + "-KRW")} KRW')

    elif returns <= -0.005:
        coins = upbit_api.get_market_list()
        for coin in coins:
            if coin == 'KRW-BTC':
                continue

            coin_balance = upbit_api.get_balance(coin)
            if coin_balance > 0:
                upbit_api.sell_market_order(coin + '-KRW', coin_balance)
                print(f'{i+1}/{num_episodes}: Loss! Sold {coin} {coin_balance} at {upbit_api.get_current_price(coin + "-KRW")} KRW')

    balance = upbit_api.get_balance('KRW')

    print(f'{i+1}/{num_episodes}: Balance: {balance} KRW, Returns: {returns}')

    if len(states) >= max_steps_per_episode:
        print(f'{i+1}/{num_episodes}: Max steps reached, terminating game')
        break

    time.sleep(1)

# 최종 잔액 출력
balance = upbit_api.get_balance('KRW')
print(f'Final balance: {balance} KRW')
